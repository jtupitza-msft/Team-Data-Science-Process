{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Fairlearn: Performing a GridSearch with Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use Fairlearn and the Fairness dashboard to\n",
    "generate predictors for the Census dataset. This dataset is a\n",
    "classification problem - given a range of data about 32,000 individuals,\n",
    "predict whether their annual income is above or below fifty thousand\n",
    "dollars per year.\n",
    "\n",
    "For the purposes of this notebook, we shall treat this as a loan\n",
    "decision problem. We will pretend that the label indicates whether or\n",
    "not each individual repaid a loan in the past. We will use the data to\n",
    "train a predictor to predict whether previously unseen individuals will\n",
    "repay a loan or not. The assumption is that the model predictions are\n",
    "used to decide whether an individual should be offered a loan.\n",
    "\n",
    "We will first train a fairness-unaware predictor and show that it leads\n",
    "to unfair decisions under a specific notion of fairness called\n",
    "*demographic parity*. We then mitigate unfairness by applying the\n",
    "`GridSearch`{.sourceCode} algorithm from the Fairlearn package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity, ErrorRate\n",
    "from fairlearn.widget import FairlearnDashboard\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48842 Observations x 14 Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass    fnlwgt     education  education-num      marital-status  \\\n",
       "0  25.0    Private  226802.0          11th            7.0       Never-married   \n",
       "1  38.0    Private   89814.0       HS-grad            9.0  Married-civ-spouse   \n",
       "2  28.0  Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse   \n",
       "3  44.0    Private  160323.0  Some-college           10.0  Married-civ-spouse   \n",
       "4  18.0        NaN  103497.0  Some-college           10.0       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male           0.0           0.0   \n",
       "1    Farming-fishing      Husband  White    Male           0.0           0.0   \n",
       "2    Protective-serv      Husband  White    Male           0.0           0.0   \n",
       "3  Machine-op-inspct      Husband  Black    Male        7688.0           0.0   \n",
       "4                NaN    Own-child  White  Female           0.0           0.0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0            40.0  United-States  \n",
       "1            50.0  United-States  \n",
       "2            40.0  United-States  \n",
       "3            40.0  United-States  \n",
       "4            30.0  United-States  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X_raw = data.data\n",
    "y = (data.target == '>50K') * 1\n",
    "\n",
    "# Take a quick look at the data\n",
    "print(\"{0} Observations x {1} Features\".format(len(X_raw), len(X_raw.columns)))\n",
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the Sensitive Feature(s)\n",
    "**Sex** is a Sensitive Feature (i.e., a feature that could lead to biased predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X_raw[\"sex\"]\n",
    "X = X_raw.drop(labels=['sex'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encode the Categorical Features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Scale the Numerical Features\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "# Use the Preprocessed Independent Features (X) to Create a Pandas DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Label Encode the Dependent (Target) Feature (y)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X_scaled, y, A,\n",
    "                                                                     test_size=0.2,\n",
    "                                                                     random_state=0,\n",
    "                                                                     stratify=y)\n",
    "\n",
    "# Work around indexing bug\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, Train an Unmitigated (Fairness-Unaware) Predictor as a Baseline:\n",
    "To demonstrate the effect of Fairlearn:\n",
    "- Train a ML predictor that does not mitigate the effects of bias\n",
    "- Load the fairness-unaware predictor into the Fairness dashboard to assess its fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "unmitigated_predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af39e89800b4fe2995e9225ecb0d77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/fairlearn/widget/_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
      "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f764c0210b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FairlearnDashboard(sensitive_features=A_test, sensitive_feature_names=['sex'],\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"unmitigated\": unmitigated_predictor.predict(X_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the disparity in accuracy, we see that males have an error\n",
    "about three times greater than the females. More interesting is the\n",
    "disparity in opportunity - males are offered loans at three times the\n",
    "rate of females.\n",
    "\n",
    "Despite the fact that we removed the feature from the training data, our\n",
    "predictor still discriminates based on sex. This demonstrates that\n",
    "simply ignoring a sensitive feature when fitting a predictor rarely\n",
    "eliminates unfairness. There will generally be enough other features\n",
    "correlated with the removed feature to lead to disparate impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, Mitigate Bias using Fairlearn GridSearch\n",
    "Supply a standard ML estimator, which is treated as a blackbox. GridSearch generates a sequence of relabellings and reweightings; training a predictor for each iteration.\n",
    "\n",
    "For this example, demographic parity (on the sensitive feature of sex) is specified as the fairness metric. Demographic parity requires that individuals are offered the opportunity (are approved for a loan in this example) independent of membership in the sensitive class (i.e., females and males should be offered loans at the same rate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
    "                   constraints=DemographicParity(), grid_size=71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithms provide `fit()`{.sourceCode} and `predict()`{.sourceCode}\n",
    "methods, so they behave in a similar manner to other ML packages in\n",
    "Python. We do however have to specify two extra arguments to\n",
    "`fit()`{.sourceCode} - the column of sensitive feature labels, and also\n",
    "the number of predictors to generate in our sweep.\n",
    "\n",
    "After `fit()`{.sourceCode} completes, we extract the full set of\n",
    "predictors from the fairlearn.reductions.GridSearch object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep.fit(X_train, y_train, sensitive_features=A_train)\n",
    "predictors = sweep.predictors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could load these predictors into the Fairness dashboard now. However,\n",
    "the plot would be somewhat confusing due to their number. In this case,\n",
    "we are going to remove the predictors which are dominated in the\n",
    "error-disparity space by others from the sweep (note that the disparity\n",
    "will only be calculated for the sensitive feature; other potentially\n",
    "sensitive features will not be mitigated). In general, one might not\n",
    "want to do this, since there may be other considerations beyond the\n",
    "strict optimization of error and disparity (of the given sensitive\n",
    "feature).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, disparities = [], []\n",
    "for m in predictors:\n",
    "    def classifier(X): return m.predict(X)\n",
    "\n",
    "    error = ErrorRate()\n",
    "    error.load_data(X_train, pd.Series(y_train), sensitive_features=A_train)\n",
    "    disparity = DemographicParity()\n",
    "    disparity.load_data(X_train, pd.Series(y_train), sensitive_features=A_train)\n",
    "\n",
    "    errors.append(error.gamma(classifier)[0])\n",
    "    disparities.append(disparity.gamma(classifier).max())\n",
    "\n",
    "all_results = pd.DataFrame({\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n",
    "\n",
    "non_dominated = []\n",
    "for row in all_results.itertuples():\n",
    "    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"] <= row.disparity]\n",
    "    if row.error <= errors_for_lower_or_eq_disparity.min():\n",
    "        non_dominated.append(row.predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put the dominant models into the Fairness dashboard,\n",
    "along with the unmitigated model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/fairlearn/widget/_fairlearn_dashboard.py:47: UserWarning: The FairlearnDashboard will move from Fairlearn to the raiwidgets package after the v0.5.0 release. Instead, Fairlearn will provide some of the existing functionality through matplotlib-based visualizations.\n",
      "  warn(\"The FairlearnDashboard will move from Fairlearn to the \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ded11d722a1493dadfbf7a8350fedcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f7642ad29e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard_predicted = {\"unmitigated\": unmitigated_predictor.predict(X_test)}\n",
    "for i in range(len(non_dominated)):\n",
    "    key = \"dominant_model_{0}\".format(i)\n",
    "    value = non_dominated[i].predict(X_test)\n",
    "    dashboard_predicted[key] = value\n",
    "\n",
    "\n",
    "FairlearnDashboard(sensitive_features=A_test, sensitive_feature_names=['sex'],\n",
    "                   y_true=y_test, y_pred=dashboard_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a Pareto front forming - the set of predictors which represent\n",
    "optimal tradeoffs between accuracy and disparity in predictions. In the\n",
    "ideal case, we would have a predictor at (1,0) - perfectly accurate and\n",
    "without any unfairness under demographic parity (with respect to the\n",
    "sensitive feature \"sex\"). The Pareto front represents the closest we can\n",
    "come to this ideal based on our data and choice of estimator. Note the\n",
    "range of the axes - the disparity axis covers more values than the\n",
    "accuracy, so we can reduce disparity substantially for a small loss in\n",
    "accuracy.\n",
    "\n",
    "By clicking on individual models on the plot, we can inspect their\n",
    "metrics for disparity and accuracy in greater detail. In a real example,\n",
    "we would then pick the model which represented the best trade-off\n",
    "between accuracy and disparity given the relevant business constraints.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
